{
  "metadata": {
    "id": "49b7a4a3-bec7-4bd4-a926-fef53506cf9b",
    "name": "CountingUniqueIds",
    "user_save_timestamp": "1970-01-01T01:00:00.000Z",
    "auto_save_timestamp": "1970-01-01T01:00:00.000Z",
    "language_info": {
      "name": "scala",
      "file_extension": "scala",
      "codemirror_mode": "text/x-scala"
    },
    "trusted": true,
    "sparkNotebook": null,
    "customLocalRepo": "/home/maasg/.ivy2/local",
    "customRepos": null,
    "customDeps": [
      "learning.spark.streaming %% hllaccumulator % 0.1.1-SNAPSHOT"
    ],
    "customImports": null,
    "customArgs": null,
    "customSparkConf": null,
    "customVars": null
  },
  "cells": [
    {
      "metadata": {
        "id": "9D292F715E104E7B88D7817FC94C7E1B"
      },
      "cell_type": "markdown",
      "source": "#Approximate Counting Unique Users in a Stream\nIn this notebook we are going to explore the use of a probabilistic data structure, HyperLogLog, to approximate the count of unique visitors in a website.\n\nFor that purpose, we are going look at the logs of an imaginary popular weblog.\nIn this job, the core logic is to track which articles are popular, by maintaing a register of the clicks received by URL and partitioned by path.\n  To keep track of the unique visitors, we will make use of accumulators, which are maintained as a parallel channel to the main streaming logic. "
    },
    {
      "metadata": {
        "id": "448179780A5F48A4922403BD69B5510D"
      },
      "cell_type": "markdown",
      "source": "__Note that, to run this notebook, the project \"hll-accumulator\" needs to be published in the local system.\nRefer to [hll-accumulator](https://github.com/LearningSparkStreaming/HLLAccumulator)__"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "AFA92D14BAD64A768C419526E46EA888"
      },
      "cell_type": "code",
      "source": "// These are the main- and sub- categories for our blog site\nval categories = Map(\"health\" -> List(\"sleep\",\"training\",\"diet\",\"meditation\"), \n                     \"science\" -> List(\"physics\", \"mechanics\", \"nature\", \"ecology\"), \n                     \"diy\" -> List(\"home_improvement\", \"robotics\", \"drones\", \"home_automation\")\n                     )\n// All topics merged\nval topics = (for {\n  mainCategory <- categories.keys\n  subCategory <- categories(mainCategory)\n} yield (s\"$mainCategory/$subCategory\")).toList\n",
      "outputs": []
    },
    {
      "metadata": {
        "id": "9046E37AF5BF443A88FEC82578163283"
      },
      "cell_type": "markdown",
      "source": "## A Simplified Domain Model\nFor this example we are going to obviate ancilliary aspects to log processing, such as user agent, ip-address, HTTP/codes, etc... Our simplified model will consist of `timestamp, userId, pathVisited`\n\nThis \"stream setup\" code can be mostly only glanced over as its only function is to generate a weighted-randomized stream of user clicks. In a \"real-life\" scenario we would get this data from a production web server."
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "907E46E518F749898C2A307B1C03A4FD"
      },
      "cell_type": "code",
      "source": "case class BlogHit(timestamp: Long, userId: String, path: String)\n",
      "outputs": []
    },
    {
      "metadata": {
        "id": "0BB085CC5B434B3C856D85BED7AD84F5"
      },
      "cell_type": "markdown",
      "source": "We are going to generate a series of random articles, some of which will become very popular"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "B80C865329864BD686C72A97898C8355"
      },
      "cell_type": "code",
      "source": "import scala.util.Random\nval generatedContent: List[(String, Double)] = {\n  val qualifiers  = \"\"\"good, new, first, last, long, great, little, own, other, old, \n  right, big, high, different, small, large, next, early, young, important, few, public, bad, same, able\"\"\".split(\",\").map(_.trim)\n  val themas = \"\"\"strawberry, screw, rice, chocolate, lettuce, sleep, wood, frame, electricity, discharge, voltage, shock, distress, \n                  anxiety, processor, memory\"\"\".split(\",\").map(_.trim)\n  val titles = for {\n    qualifier <- qualifiers\n    thema <- themas\n  } yield s\"${qualifier}_${thema}\"\n\n  val paths = for {\n       topic <- topics\n       title <- titles\n       popularity <- Some(Random.nextDouble)\n       _ <- if (Random.nextDouble() > 0.98) Some(()) else None // only 2% chance of generating this combination\n    } yield (s\"$topic/$title\",popularity) \n  paths\n}\n",
      "outputs": []
    },
    {
      "metadata": {
        "id": "50EA138D2A834EB5860957721CD48565"
      },
      "cell_type": "markdown",
      "source": "We will simulate a user visit with a randomized event. Some user with a userId visits some content if a random generated value is within the \"popularity\" \nindex, which is also represented with a probability  `0<= x <=1`"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "presentation": {
          "tabs_state": "{\n  \"tab_id\": \"#tab711025873-0\"\n}",
          "pivot_chart_state": "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
        },
        "id": "826129FAD2764D36AF51FE934902E807"
      },
      "cell_type": "code",
      "source": "val userVisit: () => Option[BlogHit] = () => {\n  val generatedContextSize = generatedContent.size\n  for {\n    userId <- Some(\"user\"+Random.nextInt(100000))\n    (content, popularity) <- generatedContent.lift(Random.nextInt(generatedContextSize))\n    chance = Random.nextDouble\n    _ <- if (chance < popularity) Some(()) else None // weight popularity of the content  \n  } yield {\n    BlogHit(System.currentTimeMillis, userId, content)\n  }\n}\n  ",
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "74A3FBA2502D406DBE989FEF933CABDA"
      },
      "cell_type": "code",
      "source": "val visitRDD = sparkContext.parallelize(List.fill(100)(userVisit))\n",
      "outputs": []
    },
    {
      "metadata": {
        "id": "AC3352665869439FACA47804E169C25A"
      },
      "cell_type": "markdown",
      "source": "## Create a stream of simulated data \n"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "4ABC1788747542FB9CCEBDBBCD1B517E"
      },
      "cell_type": "code",
      "source": "import org.apache.spark.streaming.{StreamingContext, Seconds, Minutes}\n@transient val ssc = new StreamingContext(sparkContext, Seconds(2))",
      "outputs": []
    },
    {
      "metadata": {
        "id": "1A256D51684C49A8BB7D5961504C348C"
      },
      "cell_type": "markdown",
      "source": "Using the click generation function we defined above, on each interval we are going to generate a series of \"clicks\" on content by some users. The clicks are weighted by popularity so that popular content gets more visits."
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "2A67DD8D44344414B920CEBA40DECD5C"
      },
      "cell_type": "code",
      "source": "import org.apache.spark.streaming.dstream.ConstantInputDStream\n@transient val clickStream = new ConstantInputDStream(ssc, visitRDD).flatMap(e=>e())",
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "8751ECA71C7F45298494986D64917B35"
      },
      "cell_type": "code",
      "source": "@transient val topUrlsChart = CustomPlotlyChart(Seq[(String,Int)](), \n                            dataOptions=\"{type: 'bar'}\",\n                            dataSources=\"{x: '_1', y: '_2'}\")\n@transient val uniqueUsersChart = CustomPlotlyChart(Seq[(Long, Long)](), \n                            dataOptions=\"{type: 'line'}\",\n                            dataSources=\"{x: '_1', y: '_2'}\")\n",
      "outputs": []
    },
    {
      "metadata": {
        "id": "9A78424A92A74DCFB336CBAF570A4C2B"
      },
      "cell_type": "markdown",
      "source": "# Define the unique visitors accumulator\n"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "33EF4283CC73440C8679B6343383EF39"
      },
      "cell_type": "code",
      "source": "import learning.spark.streaming.HLLAccumulator\nval uniqueVisitorsAccumulator = new HLLAccumulator[String]()\nsc.register(uniqueVisitorsAccumulator, \"unique-visitors\")",
      "outputs": []
    },
    {
      "metadata": {
        "id": "F5B5D311DB8641E988ADBD30737E68DD"
      },
      "cell_type": "markdown",
      "source": "# Windowed Trends\n\nWe will use the knowledge we recently acquired about sliding windows to create a view of recent trends of our website traffic.\nBefore decomposing the Click info into a URL count, we will also add the userId to our accumulator to register the userId of the click."
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "11D7AC5D84FE4578AD30F21D181B030A"
      },
      "cell_type": "code",
      "source": "clickStream.foreachRDD{rdd => \n                       rdd.foreach{case BlogHit(ts, user, url) => uniqueVisitorsAccumulator.add(user)}\n                       val currentTime = (System.currentTimeMillis / 1000) % (60*60*24) // get the hour part of the current timestamp in seconds\n                       val currentUniqueVisitors = uniqueVisitorsAccumulator.value\n                       uniqueUsersChart.addAndApply(Seq((currentTime, currentUniqueVisitors)))\n                      }",
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "B42F6DD790644EB09ACEC4D4188429A3"
      },
      "cell_type": "code",
      "source": "@transient val trendStream = clickStream.map{case BlogHit(ts, user, url) =>  (url,1)}\n                  .reduceByKeyAndWindow((count:Int, agg:Int) => count + agg, Minutes(5), Seconds(2)) ",
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "ABFFE3FC45404A398252A46A1DBEC3D5"
      },
      "cell_type": "code",
      "source": "trendStream.foreachRDD{rdd => \n                       val top10URLs = rdd.map(_.swap).sortByKey(ascending = false).take(10).map(_.swap)\n                       topUrlsChart.applyOn(top10URLs)\n                      }",
      "outputs": []
    },
    {
      "metadata": {
        "id": "D5BF21497EC3462D81668776014C6671"
      },
      "cell_type": "markdown",
      "source": "## Top URLs Chart\n(charts will update once the Streaming job is started)"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "1B54BDC1D9734536B61540F7275B52EE"
      },
      "cell_type": "code",
      "source": "topUrlsChart",
      "outputs": []
    },
    {
      "metadata": {
        "id": "8707383E034B4D9D9155BD6301E2C6A4"
      },
      "cell_type": "markdown",
      "source": "## Unique Users Chart\n(charts will update once the Streaming job is started)"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "7ED5D91408CE4B4883FC1F1659C68206"
      },
      "cell_type": "code",
      "source": "uniqueUsersChart",
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "0B654D4F097E4D9E89FEA1582F775ABE"
      },
      "cell_type": "code",
      "source": "ssc.start()",
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false,
        "id": "C3837F2D182C4F8C840126C7C33D2C5E"
      },
      "cell_type": "code",
      "source": "// only stop the content after we are done exploring the data stream\n// ssc.stop(false)",
      "outputs": [
        {
          "metadata": {},
          "data": {
            "text/html": ""
          },
          "output_type": "execute_result",
          "execution_count": 109,
          "time": "Took: 0.622s, at 2017-07-3 03:01"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": true,
        "collapsed": true,
        "id": "9916A8DD876E45379869BFFD5FED5D19"
      },
      "cell_type": "code",
      "source": "",
      "outputs": []
    }
  ],
  "nbformat": 4
}